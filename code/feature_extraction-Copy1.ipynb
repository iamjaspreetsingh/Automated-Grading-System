{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "stop_words=set(stopwords.words('english'))\n",
    "lemm = WordNetLemmatizer()\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "lines=100000\n",
    "from nltk.corpus import stopwords\n",
    "stop = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel(r\"C:\\Users\\PIYUSH\\Downloads\\AG\\training_set_rel3.xlsx\",sheet_name=\"training_set\")\n",
    "data_val = pd.read_excel(r\"C:\\Users\\PIYUSH\\Downloads\\AG\\valid_set.xlsx\",sheet_name=\"valid_set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>rater1_domain1</th>\n",
       "      <th>rater2_domain1</th>\n",
       "      <th>rater3_domain1</th>\n",
       "      <th>domain1_score</th>\n",
       "      <th>rater1_domain2</th>\n",
       "      <th>rater2_domain2</th>\n",
       "      <th>domain2_score</th>\n",
       "      <th>...</th>\n",
       "      <th>rater2_trait3</th>\n",
       "      <th>rater2_trait4</th>\n",
       "      <th>rater2_trait5</th>\n",
       "      <th>rater2_trait6</th>\n",
       "      <th>rater3_trait1</th>\n",
       "      <th>rater3_trait2</th>\n",
       "      <th>rater3_trait3</th>\n",
       "      <th>rater3_trait4</th>\n",
       "      <th>rater3_trait5</th>\n",
       "      <th>rater3_trait6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear local newspaper, I think effects computer...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @CAPS1 @CAPS2, I believe that using compu...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Local Newspaper, @CAPS1 I have found that...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @LOCATION1, I know having computers has a...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   essay_id  essay_set                                              essay  \\\n",
       "0         1          1  Dear local newspaper, I think effects computer...   \n",
       "1         2          1  Dear @CAPS1 @CAPS2, I believe that using compu...   \n",
       "2         3          1  Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...   \n",
       "3         4          1  Dear Local Newspaper, @CAPS1 I have found that...   \n",
       "4         5          1  Dear @LOCATION1, I know having computers has a...   \n",
       "\n",
       "   rater1_domain1  rater2_domain1  rater3_domain1  domain1_score  \\\n",
       "0             4.0             4.0             NaN            8.0   \n",
       "1             5.0             4.0             NaN            9.0   \n",
       "2             4.0             3.0             NaN            7.0   \n",
       "3             5.0             5.0             NaN           10.0   \n",
       "4             4.0             4.0             NaN            8.0   \n",
       "\n",
       "   rater1_domain2  rater2_domain2  domain2_score  ...  rater2_trait3  \\\n",
       "0             NaN             NaN            NaN  ...            NaN   \n",
       "1             NaN             NaN            NaN  ...            NaN   \n",
       "2             NaN             NaN            NaN  ...            NaN   \n",
       "3             NaN             NaN            NaN  ...            NaN   \n",
       "4             NaN             NaN            NaN  ...            NaN   \n",
       "\n",
       "   rater2_trait4  rater2_trait5  rater2_trait6  rater3_trait1  rater3_trait2  \\\n",
       "0            NaN            NaN            NaN            NaN            NaN   \n",
       "1            NaN            NaN            NaN            NaN            NaN   \n",
       "2            NaN            NaN            NaN            NaN            NaN   \n",
       "3            NaN            NaN            NaN            NaN            NaN   \n",
       "4            NaN            NaN            NaN            NaN            NaN   \n",
       "\n",
       "   rater3_trait3  rater3_trait4  rater3_trait5  rater3_trait6  \n",
       "0            NaN            NaN            NaN            NaN  \n",
       "1            NaN            NaN            NaN            NaN  \n",
       "2            NaN            NaN            NaN            NaN  \n",
       "3            NaN            NaN            NaN            NaN  \n",
       "4            NaN            NaN            NaN            NaN  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>domain1_predictionid</th>\n",
       "      <th>domain2_predictionid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1788</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @ORGANIZATION1, @CAPS1 more and more peop...</td>\n",
       "      <td>1788</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1789</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @LOCATION1 Time @CAPS1 me tell you what I...</td>\n",
       "      <td>1789</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1790</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Local newspaper, Have you been spending a...</td>\n",
       "      <td>1790</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1791</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Readers, @CAPS1 you imagine how life woul...</td>\n",
       "      <td>1791</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1792</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear newspaper, I strongly believe that comput...</td>\n",
       "      <td>1792</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   essay_id  essay_set                                              essay  \\\n",
       "0      1788          1  Dear @ORGANIZATION1, @CAPS1 more and more peop...   \n",
       "1      1789          1  Dear @LOCATION1 Time @CAPS1 me tell you what I...   \n",
       "2      1790          1  Dear Local newspaper, Have you been spending a...   \n",
       "3      1791          1  Dear Readers, @CAPS1 you imagine how life woul...   \n",
       "4      1792          1  Dear newspaper, I strongly believe that comput...   \n",
       "\n",
       "   domain1_predictionid  domain2_predictionid  \n",
       "0                  1788                   NaN  \n",
       "1                  1789                   NaN  \n",
       "2                  1790                   NaN  \n",
       "3                  1791                   NaN  \n",
       "4                  1792                   NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word(data):\n",
    "    lexicon=[]\n",
    "    for i in data[\"essay\"]:\n",
    "        all_words=word_tokenize(i)\n",
    "        #all_words=[i for i in all_words if i not in stop]\n",
    "        all_words=[lemm.lemmatize(j.lower()) for j in all_words]\n",
    "        lexicon.append(len(all_words))\n",
    "    return lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls=word(data)\n",
    "data[\"word_count\"]=ls\n",
    "ls=word(data_val)\n",
    "data_val[\"word_count\"]=ls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>domain1_predictionid</th>\n",
       "      <th>domain2_predictionid</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1788</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @ORGANIZATION1, @CAPS1 more and more peop...</td>\n",
       "      <td>1788</td>\n",
       "      <td>NaN</td>\n",
       "      <td>275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1789</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @LOCATION1 Time @CAPS1 me tell you what I...</td>\n",
       "      <td>1789</td>\n",
       "      <td>NaN</td>\n",
       "      <td>353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1790</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Local newspaper, Have you been spending a...</td>\n",
       "      <td>1790</td>\n",
       "      <td>NaN</td>\n",
       "      <td>471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1791</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Readers, @CAPS1 you imagine how life woul...</td>\n",
       "      <td>1791</td>\n",
       "      <td>NaN</td>\n",
       "      <td>410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1792</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear newspaper, I strongly believe that comput...</td>\n",
       "      <td>1792</td>\n",
       "      <td>NaN</td>\n",
       "      <td>496</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   essay_id  essay_set                                              essay  \\\n",
       "0      1788          1  Dear @ORGANIZATION1, @CAPS1 more and more peop...   \n",
       "1      1789          1  Dear @LOCATION1 Time @CAPS1 me tell you what I...   \n",
       "2      1790          1  Dear Local newspaper, Have you been spending a...   \n",
       "3      1791          1  Dear Readers, @CAPS1 you imagine how life woul...   \n",
       "4      1792          1  Dear newspaper, I strongly believe that comput...   \n",
       "\n",
       "   domain1_predictionid  domain2_predictionid  word_count  \n",
       "0                  1788                   NaN         275  \n",
       "1                  1789                   NaN         353  \n",
       "2                  1790                   NaN         471  \n",
       "3                  1791                   NaN         410  \n",
       "4                  1792                   NaN         496  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vocab(data):\n",
    "    lexicon=[]\n",
    "    ls=[]\n",
    "    for i in data[\"essay\"]:\n",
    "        all_words=word_tokenize(i)\n",
    "        all_words=[i for i in all_words if i not in stop]\n",
    "        all_words=[word.lower() for word in all_words if word.isalpha()]\n",
    "        all_words=[lemm.lemmatize(j.lower()) for j in all_words]\n",
    "        lexicon.append(all_words)\n",
    "    for i in range(data.shape[0]):\n",
    "        ls.append(len(set(lexicon[i])))\n",
    "    return ls\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls=vocab(data)\n",
    "data[\"vocab_count\"]=ls\n",
    "ls=vocab(data_val)\n",
    "data_val[\"vocab_count\"]=ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>rater1_domain1</th>\n",
       "      <th>rater2_domain1</th>\n",
       "      <th>rater3_domain1</th>\n",
       "      <th>domain1_score</th>\n",
       "      <th>rater1_domain2</th>\n",
       "      <th>rater2_domain2</th>\n",
       "      <th>domain2_score</th>\n",
       "      <th>...</th>\n",
       "      <th>rater2_trait5</th>\n",
       "      <th>rater2_trait6</th>\n",
       "      <th>rater3_trait1</th>\n",
       "      <th>rater3_trait2</th>\n",
       "      <th>rater3_trait3</th>\n",
       "      <th>rater3_trait4</th>\n",
       "      <th>rater3_trait5</th>\n",
       "      <th>rater3_trait6</th>\n",
       "      <th>word_count</th>\n",
       "      <th>vocab_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear local newspaper, I think effects computer...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>386</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @CAPS1 @CAPS2, I believe that using compu...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>464</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>313</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Local Newspaper, @CAPS1 I have found that...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>611</td>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @LOCATION1, I know having computers has a...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>517</td>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   essay_id  essay_set                                              essay  \\\n",
       "0         1          1  Dear local newspaper, I think effects computer...   \n",
       "1         2          1  Dear @CAPS1 @CAPS2, I believe that using compu...   \n",
       "2         3          1  Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...   \n",
       "3         4          1  Dear Local Newspaper, @CAPS1 I have found that...   \n",
       "4         5          1  Dear @LOCATION1, I know having computers has a...   \n",
       "\n",
       "   rater1_domain1  rater2_domain1  rater3_domain1  domain1_score  \\\n",
       "0             4.0             4.0             NaN            8.0   \n",
       "1             5.0             4.0             NaN            9.0   \n",
       "2             4.0             3.0             NaN            7.0   \n",
       "3             5.0             5.0             NaN           10.0   \n",
       "4             4.0             4.0             NaN            8.0   \n",
       "\n",
       "   rater1_domain2  rater2_domain2  domain2_score     ...       rater2_trait5  \\\n",
       "0             NaN             NaN            NaN     ...                 NaN   \n",
       "1             NaN             NaN            NaN     ...                 NaN   \n",
       "2             NaN             NaN            NaN     ...                 NaN   \n",
       "3             NaN             NaN            NaN     ...                 NaN   \n",
       "4             NaN             NaN            NaN     ...                 NaN   \n",
       "\n",
       "   rater2_trait6  rater3_trait1  rater3_trait2  rater3_trait3  rater3_trait4  \\\n",
       "0            NaN            NaN            NaN            NaN            NaN   \n",
       "1            NaN            NaN            NaN            NaN            NaN   \n",
       "2            NaN            NaN            NaN            NaN            NaN   \n",
       "3            NaN            NaN            NaN            NaN            NaN   \n",
       "4            NaN            NaN            NaN            NaN            NaN   \n",
       "\n",
       "   rater3_trait5  rater3_trait6  word_count  vocab_count  \n",
       "0            NaN            NaN         386          103  \n",
       "1            NaN            NaN         464          129  \n",
       "2            NaN            NaN         313           92  \n",
       "3            NaN            NaN         611          169  \n",
       "4            NaN            NaN         517          131  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos(data):\n",
    "    lexicon=[]\n",
    "    noun=0\n",
    "    verb=0\n",
    "    adj=0\n",
    "    adv=0\n",
    "    n_count=[]\n",
    "    v_count=[]\n",
    "    adj_count=[]\n",
    "    adv_count=[]\n",
    "    for i in data[\"essay\"]:\n",
    "        tokenized = sent_tokenize(i)\n",
    "        for j in tokenized:\n",
    "            all_words=word_tokenize(j)\n",
    "            all_words=[k for k in all_words if k not in stop]\n",
    "            tagged = nltk.pos_tag(all_words)\n",
    "            for t in tagged:\n",
    "\n",
    "                if (t[1][0])=='N':\n",
    "                    noun+=1\n",
    "                if (t[1][0])=='V':\n",
    "                    verb+=1\n",
    "                if (t[1][0])=='R':\n",
    "                    adv+=1\n",
    "                if (t[1][0])=='J':\n",
    "                    adj+=1\n",
    "        n_count.append(noun)\n",
    "        v_count.append(verb)\n",
    "        adj_count.append(adj)\n",
    "        adv_count.append(adv)\n",
    "        noun=0\n",
    "        verb=0\n",
    "        adv=0\n",
    "        adj=0\n",
    "    return  (n_count, v_count, adj_count, adv_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['n_count'], data['v_count'], data['adj_count'], data['adv_count']=pos(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_val['n_count'], data_val['v_count'], data_val['adj_count'], data_val['adv_count']=pos(data_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>domain1_predictionid</th>\n",
       "      <th>domain2_predictionid</th>\n",
       "      <th>word_count</th>\n",
       "      <th>vocab_count</th>\n",
       "      <th>n_count</th>\n",
       "      <th>v_count</th>\n",
       "      <th>adj_count</th>\n",
       "      <th>adv_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1788</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @ORGANIZATION1, @CAPS1 more and more peop...</td>\n",
       "      <td>1788</td>\n",
       "      <td>NaN</td>\n",
       "      <td>275</td>\n",
       "      <td>77</td>\n",
       "      <td>67</td>\n",
       "      <td>29</td>\n",
       "      <td>21</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1789</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @LOCATION1 Time @CAPS1 me tell you what I...</td>\n",
       "      <td>1789</td>\n",
       "      <td>NaN</td>\n",
       "      <td>353</td>\n",
       "      <td>95</td>\n",
       "      <td>75</td>\n",
       "      <td>35</td>\n",
       "      <td>15</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1790</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Local newspaper, Have you been spending a...</td>\n",
       "      <td>1790</td>\n",
       "      <td>NaN</td>\n",
       "      <td>471</td>\n",
       "      <td>137</td>\n",
       "      <td>91</td>\n",
       "      <td>51</td>\n",
       "      <td>29</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1791</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Readers, @CAPS1 you imagine how life woul...</td>\n",
       "      <td>1791</td>\n",
       "      <td>NaN</td>\n",
       "      <td>410</td>\n",
       "      <td>103</td>\n",
       "      <td>103</td>\n",
       "      <td>49</td>\n",
       "      <td>21</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1792</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear newspaper, I strongly believe that comput...</td>\n",
       "      <td>1792</td>\n",
       "      <td>NaN</td>\n",
       "      <td>496</td>\n",
       "      <td>132</td>\n",
       "      <td>122</td>\n",
       "      <td>39</td>\n",
       "      <td>38</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   essay_id  essay_set                                              essay  \\\n",
       "0      1788          1  Dear @ORGANIZATION1, @CAPS1 more and more peop...   \n",
       "1      1789          1  Dear @LOCATION1 Time @CAPS1 me tell you what I...   \n",
       "2      1790          1  Dear Local newspaper, Have you been spending a...   \n",
       "3      1791          1  Dear Readers, @CAPS1 you imagine how life woul...   \n",
       "4      1792          1  Dear newspaper, I strongly believe that comput...   \n",
       "\n",
       "   domain1_predictionid  domain2_predictionid  word_count  vocab_count  \\\n",
       "0                  1788                   NaN         275           77   \n",
       "1                  1789                   NaN         353           95   \n",
       "2                  1790                   NaN         471          137   \n",
       "3                  1791                   NaN         410          103   \n",
       "4                  1792                   NaN         496          132   \n",
       "\n",
       "   n_count  v_count  adj_count  adv_count  \n",
       "0       67       29         21         15  \n",
       "1       75       35         15         21  \n",
       "2       91       51         29         26  \n",
       "3      103       49         21         17  \n",
       "4      122       39         38         22  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent_len(data):\n",
    "    sent=[]\n",
    "    for i in data[\"essay\"]:\n",
    "        tokenized = sent_tokenize(i)\n",
    "        sent.append(len(tokenized))\n",
    "    return sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"sent_len\"]=sent_len(data)\n",
    "data_val[\"sent_len\"]=sent_len(data_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bow(data):\n",
    "    lexicon=[]\n",
    "    dict1={}\n",
    "    prev=1\n",
    "    for i in range(1,9):\n",
    "        dict1[i]=[\"student\"]\n",
    "    for i,j in enumerate(data[\"essay_set\"]):\n",
    "        tokenized=sent_tokenize(data[\"essay\"].iloc[i])\n",
    "        for k in tokenized:\n",
    "            all_words=word_tokenize(k)\n",
    "            all_words=[i for i in all_words if i not in stop]\n",
    "            tagged = nltk.pos_tag(all_words)\n",
    "            all_words=[i[0] for i in tagged if (i[1][0]==\"N\" or i[1][0]==\"V\"  or i[1][0]==\"J\")]\n",
    "            all_words=[lemm.lemmatize(j.lower()) for j in all_words]\n",
    "            dict1[j]+=all_words\n",
    "    return dict1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict1=bow(data)\n",
    "dict2=bow(data_val)\n",
    "def poping(w_counts):\n",
    "    w_counts.pop('@',None)\n",
    "    w_counts.pop('CAPS1',None)\n",
    "    w_counts.pop('CAPS2',None)\n",
    "    w_counts.pop('CAPS3',None)\n",
    "    w_counts.pop('CAPS4',None)\n",
    "    w_counts.pop('CAPS5',None)\n",
    "    w_counts.pop('NUM1',None)\n",
    "    w_counts.pop('”',None)\n",
    "    w_counts.pop('“',None)\n",
    "    w_counts.pop('’',None)\n",
    "    w_counts.pop('caps1',None)\n",
    "    w_counts.pop('caps2',None)\n",
    "    w_counts.pop('caps3',None)\n",
    "    w_counts.pop('caps4',None)\n",
    "    w_counts.pop('caps5',None)\n",
    "    w_counts.pop('person1',None)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freek(dict):\n",
    "    res={}\n",
    "    for l in range(1,9):\n",
    "        w_counts = Counter(dict[l])\n",
    "        poping(w_counts)\n",
    "        ls=[]\n",
    "        l2=[]\n",
    "        l3=[]\n",
    "        key=[]\n",
    "        c=0\n",
    "        for i in w_counts:\n",
    "            l2.append(w_counts[i])\n",
    "        l2.sort(reverse=True)\n",
    "        l3=l2[0:10]\n",
    "        for name, age in w_counts.items():    # for name, age in dictionary.iteritems():  (for Python 2.x)\n",
    "            if age in l3:\n",
    "                key.append(name)\n",
    "        res[l]=key \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls1=freek(dict1)\n",
    "ls2=freek(dict2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freek_make(res,data):\n",
    "    b=1\n",
    "    flag=1\n",
    "    count=0\n",
    "    ls=[]\n",
    "    for i in range(data.shape[0]):\n",
    "        count=0\n",
    "        b=data[\"essay_set\"].iloc[i]\n",
    "        all_words=word_tokenize(data[\"essay\"].iloc[i])\n",
    "        all_words=[i for i in all_words if i not in stop]\n",
    "        all_words=[word.lower() for word in all_words if word.isalpha()]\n",
    "        all_words=[lemm.lemmatize(j.lower()) for j in all_words]\n",
    "       # print(all_words)\n",
    "        for word in all_words:\n",
    "            if word in res[b]:\n",
    "                count+=1\n",
    "        ls.append(count)\n",
    "    return ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls1=freek_make(ls1,data)\n",
    "ls2=freek_make(ls2,data_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"freek\"]=ls1\n",
    "data_val[\"freek\"]=ls2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet\n",
    "def spell_check(data):\n",
    "    ls=[]\n",
    "    sp=[]\n",
    "    c=0\n",
    "    for i in data[\"essay\"]:\n",
    "        all_words=word_tokenize(i)\n",
    "        all_words=[word.lower() for word in all_words if word.isalpha()]\n",
    "        all_words=[i for i in all_words if i not in stop]\n",
    "        all_words=[lemm.lemmatize(j.lower()) for j in all_words]\n",
    "        for word in all_words:\n",
    "            if(not(wordnet.synsets(word))):\n",
    "                c+=1\n",
    "        l=len(all_words)\n",
    "        corr_perc=(c/l)*100\n",
    "        sp.append(corr_perc)\n",
    "        c=0\n",
    "    return sp\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"wrong_spell\"]=spell_check(data)\n",
    "data_val[\"wrong_spell\"]=spell_check(data_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>domain1_predictionid</th>\n",
       "      <th>domain2_predictionid</th>\n",
       "      <th>word_count</th>\n",
       "      <th>vocab_count</th>\n",
       "      <th>n_count</th>\n",
       "      <th>v_count</th>\n",
       "      <th>adj_count</th>\n",
       "      <th>adv_count</th>\n",
       "      <th>sent_len</th>\n",
       "      <th>freek</th>\n",
       "      <th>wrong_spell</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1788</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @ORGANIZATION1, @CAPS1 more and more peop...</td>\n",
       "      <td>1788</td>\n",
       "      <td>NaN</td>\n",
       "      <td>275</td>\n",
       "      <td>77</td>\n",
       "      <td>67</td>\n",
       "      <td>29</td>\n",
       "      <td>21</td>\n",
       "      <td>15</td>\n",
       "      <td>13</td>\n",
       "      <td>26</td>\n",
       "      <td>8.771930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1789</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @LOCATION1 Time @CAPS1 me tell you what I...</td>\n",
       "      <td>1789</td>\n",
       "      <td>NaN</td>\n",
       "      <td>353</td>\n",
       "      <td>95</td>\n",
       "      <td>75</td>\n",
       "      <td>35</td>\n",
       "      <td>15</td>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "      <td>33</td>\n",
       "      <td>1.526718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1790</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Local newspaper, Have you been spending a...</td>\n",
       "      <td>1790</td>\n",
       "      <td>NaN</td>\n",
       "      <td>471</td>\n",
       "      <td>137</td>\n",
       "      <td>91</td>\n",
       "      <td>51</td>\n",
       "      <td>29</td>\n",
       "      <td>26</td>\n",
       "      <td>15</td>\n",
       "      <td>35</td>\n",
       "      <td>13.170732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1791</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Readers, @CAPS1 you imagine how life woul...</td>\n",
       "      <td>1791</td>\n",
       "      <td>NaN</td>\n",
       "      <td>410</td>\n",
       "      <td>103</td>\n",
       "      <td>103</td>\n",
       "      <td>49</td>\n",
       "      <td>21</td>\n",
       "      <td>17</td>\n",
       "      <td>24</td>\n",
       "      <td>31</td>\n",
       "      <td>4.733728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1792</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear newspaper, I strongly believe that comput...</td>\n",
       "      <td>1792</td>\n",
       "      <td>NaN</td>\n",
       "      <td>496</td>\n",
       "      <td>132</td>\n",
       "      <td>122</td>\n",
       "      <td>39</td>\n",
       "      <td>38</td>\n",
       "      <td>22</td>\n",
       "      <td>34</td>\n",
       "      <td>47</td>\n",
       "      <td>4.824561</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   essay_id  essay_set                                              essay  \\\n",
       "0      1788          1  Dear @ORGANIZATION1, @CAPS1 more and more peop...   \n",
       "1      1789          1  Dear @LOCATION1 Time @CAPS1 me tell you what I...   \n",
       "2      1790          1  Dear Local newspaper, Have you been spending a...   \n",
       "3      1791          1  Dear Readers, @CAPS1 you imagine how life woul...   \n",
       "4      1792          1  Dear newspaper, I strongly believe that comput...   \n",
       "\n",
       "   domain1_predictionid  domain2_predictionid  word_count  vocab_count  \\\n",
       "0                  1788                   NaN         275           77   \n",
       "1                  1789                   NaN         353           95   \n",
       "2                  1790                   NaN         471          137   \n",
       "3                  1791                   NaN         410          103   \n",
       "4                  1792                   NaN         496          132   \n",
       "\n",
       "   n_count  v_count  adj_count  adv_count  sent_len  freek  wrong_spell  \n",
       "0       67       29         21         15        13     26     8.771930  \n",
       "1       75       35         15         21        20     33     1.526718  \n",
       "2       91       51         29         26        15     35    13.170732  \n",
       "3      103       49         21         17        24     31     4.733728  \n",
       "4      122       39         38         22        34     47     4.824561  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beauty(data):\n",
    "\n",
    "    lexicon=[]\n",
    "    c=0\n",
    "    for i in data[\"essay\"]:\n",
    "        all_words=word_tokenize(i)\n",
    "        all_words=[i for i in all_words if i not in stop]\n",
    "        all_words=[word.lower() for word in all_words if word.isalpha()]\n",
    "        all_words=[lemm.lemmatize(j.lower()) for j in all_words]\n",
    "        for i in all_words:\n",
    "            if len(i)>7:\n",
    "                c+=1\n",
    "        lexicon.append(c)\n",
    "        c=0\n",
    "    return lexicon\n",
    "\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"beaut\"]=beauty(data)\n",
    "data_val[\"beaut\"]=beauty(data_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>rater1_domain1</th>\n",
       "      <th>rater2_domain1</th>\n",
       "      <th>rater3_domain1</th>\n",
       "      <th>domain1_score</th>\n",
       "      <th>rater1_domain2</th>\n",
       "      <th>rater2_domain2</th>\n",
       "      <th>domain2_score</th>\n",
       "      <th>...</th>\n",
       "      <th>word_count</th>\n",
       "      <th>vocab_count</th>\n",
       "      <th>n_count</th>\n",
       "      <th>v_count</th>\n",
       "      <th>adj_count</th>\n",
       "      <th>adv_count</th>\n",
       "      <th>sent_len</th>\n",
       "      <th>freek</th>\n",
       "      <th>wrong_spell</th>\n",
       "      <th>beaut</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear local newspaper, I think effects computer...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>386</td>\n",
       "      <td>103</td>\n",
       "      <td>84</td>\n",
       "      <td>39</td>\n",
       "      <td>24</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>25</td>\n",
       "      <td>7.333333</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @CAPS1 @CAPS2, I believe that using compu...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>464</td>\n",
       "      <td>129</td>\n",
       "      <td>117</td>\n",
       "      <td>61</td>\n",
       "      <td>21</td>\n",
       "      <td>15</td>\n",
       "      <td>20</td>\n",
       "      <td>36</td>\n",
       "      <td>8.920188</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>313</td>\n",
       "      <td>92</td>\n",
       "      <td>85</td>\n",
       "      <td>33</td>\n",
       "      <td>21</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>34</td>\n",
       "      <td>3.100775</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Local Newspaper, @CAPS1 I have found that...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>611</td>\n",
       "      <td>169</td>\n",
       "      <td>205</td>\n",
       "      <td>63</td>\n",
       "      <td>46</td>\n",
       "      <td>14</td>\n",
       "      <td>27</td>\n",
       "      <td>40</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @LOCATION1, I know having computers has a...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>517</td>\n",
       "      <td>131</td>\n",
       "      <td>115</td>\n",
       "      <td>50</td>\n",
       "      <td>23</td>\n",
       "      <td>21</td>\n",
       "      <td>30</td>\n",
       "      <td>40</td>\n",
       "      <td>12.442396</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   essay_id  essay_set                                              essay  \\\n",
       "0         1          1  Dear local newspaper, I think effects computer...   \n",
       "1         2          1  Dear @CAPS1 @CAPS2, I believe that using compu...   \n",
       "2         3          1  Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...   \n",
       "3         4          1  Dear Local Newspaper, @CAPS1 I have found that...   \n",
       "4         5          1  Dear @LOCATION1, I know having computers has a...   \n",
       "\n",
       "   rater1_domain1  rater2_domain1  rater3_domain1  domain1_score  \\\n",
       "0             4.0             4.0             NaN            8.0   \n",
       "1             5.0             4.0             NaN            9.0   \n",
       "2             4.0             3.0             NaN            7.0   \n",
       "3             5.0             5.0             NaN           10.0   \n",
       "4             4.0             4.0             NaN            8.0   \n",
       "\n",
       "   rater1_domain2  rater2_domain2  domain2_score  ...    word_count  \\\n",
       "0             NaN             NaN            NaN  ...           386   \n",
       "1             NaN             NaN            NaN  ...           464   \n",
       "2             NaN             NaN            NaN  ...           313   \n",
       "3             NaN             NaN            NaN  ...           611   \n",
       "4             NaN             NaN            NaN  ...           517   \n",
       "\n",
       "   vocab_count  n_count  v_count  adj_count  adv_count  sent_len  freek  \\\n",
       "0          103       84       39         24         11        16     25   \n",
       "1          129      117       61         21         15        20     36   \n",
       "2           92       85       33         21          6        14     34   \n",
       "3          169      205       63         46         14        27     40   \n",
       "4          131      115       50         23         21        30     40   \n",
       "\n",
       "   wrong_spell  beaut  \n",
       "0     7.333333     29  \n",
       "1     8.920188     44  \n",
       "2     3.100775     29  \n",
       "3    12.500000     68  \n",
       "4    12.442396     49  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import math\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perplexity:\n",
    "        def __init__(self):\n",
    "            self.num_words = None\n",
    "            self.counts = None\n",
    "            self.vectorizer = None\n",
    "\n",
    "        def create_counts(self, compressed_essays):\n",
    "            self.vectorizer = CountVectorizer().fit(compressed_essays)\n",
    "            self.counts = self.vectorizer.transform(compressed_essays).toarray()[0]\n",
    "\n",
    "            # length added for LaPlace smoothing\n",
    "            self.num_words = float(sum(self.counts) + len(self.counts))\n",
    "\n",
    "        def fill_perplexity_columns(self,essay_strings,df):\n",
    "            print (\"Creating ngram counts...\")\n",
    "            ls=[]\n",
    "            self.create_counts([essay_strings])\n",
    "\n",
    "            for essay in df:\n",
    "                perp = self.perplexity(essay)\n",
    "                ls.append(perp)\n",
    "            return ls\n",
    "\n",
    "        # After having already fit model on a set of training essays, calculates the\n",
    "        # perplexity of a student's essay based from the model, and returns this\n",
    "        # perplexity to be used as a feature\n",
    "        def perplexity(self, test_essay):\n",
    "            log_prob = 0.0\n",
    "            word_list = test_essay.split()\n",
    "            for word in word_list:\n",
    "                if word in self.vectorizer.vocabulary_:\n",
    "                    log_prob += math.log( (self.counts[self.vectorizer.vocabulary_[word]] + 1.0) / self.num_words)\n",
    "                else:\n",
    "                    log_prob += math.log (1.0 / self.num_words)\n",
    "\n",
    "            return math.pow(2.0, -log_prob / len(word_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_perp(data):\n",
    "    essays_string=\"\"\n",
    "    perp=Perplexity()\n",
    "    result=[]\n",
    "    for i in range(1,9):\n",
    "        df= ((data[data['essay_set'] == i]))[\"essay\"]\n",
    "        for j in df:\n",
    "            essays_string += (\" \".join(re.sub('[^a-zA-Z\\d\\s]', '', j).lower().split()))\n",
    "        r=perp.fill_perplexity_columns(essays_string,df)\n",
    "        result.append(r)\n",
    "    flat = [x for sublist in result for x in sublist]\n",
    "    return flat\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating ngram counts...\n",
      "Creating ngram counts...\n",
      "Creating ngram counts...\n",
      "Creating ngram counts...\n",
      "Creating ngram counts...\n",
      "Creating ngram counts...\n",
      "Creating ngram counts...\n",
      "Creating ngram counts...\n",
      "Creating ngram counts...\n",
      "Creating ngram counts...\n",
      "Creating ngram counts...\n",
      "Creating ngram counts...\n",
      "Creating ngram counts...\n",
      "Creating ngram counts...\n",
      "Creating ngram counts...\n",
      "Creating ngram counts...\n"
     ]
    }
   ],
   "source": [
    "data[\"perplexity\"]=make_perp(data)\n",
    "data_val[\"perplexity\"]=make_perp(data_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>domain1_predictionid</th>\n",
       "      <th>domain2_predictionid</th>\n",
       "      <th>word_count</th>\n",
       "      <th>vocab_count</th>\n",
       "      <th>n_count</th>\n",
       "      <th>v_count</th>\n",
       "      <th>adj_count</th>\n",
       "      <th>adv_count</th>\n",
       "      <th>sent_len</th>\n",
       "      <th>freek</th>\n",
       "      <th>wrong_spell</th>\n",
       "      <th>beaut</th>\n",
       "      <th>perplexity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1788</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @ORGANIZATION1, @CAPS1 more and more peop...</td>\n",
       "      <td>1788</td>\n",
       "      <td>NaN</td>\n",
       "      <td>275</td>\n",
       "      <td>77</td>\n",
       "      <td>67</td>\n",
       "      <td>29</td>\n",
       "      <td>21</td>\n",
       "      <td>15</td>\n",
       "      <td>13</td>\n",
       "      <td>26</td>\n",
       "      <td>8.771930</td>\n",
       "      <td>26</td>\n",
       "      <td>163.218737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1789</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @LOCATION1 Time @CAPS1 me tell you what I...</td>\n",
       "      <td>1789</td>\n",
       "      <td>NaN</td>\n",
       "      <td>353</td>\n",
       "      <td>95</td>\n",
       "      <td>75</td>\n",
       "      <td>35</td>\n",
       "      <td>15</td>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "      <td>33</td>\n",
       "      <td>1.526718</td>\n",
       "      <td>25</td>\n",
       "      <td>154.934685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1790</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Local newspaper, Have you been spending a...</td>\n",
       "      <td>1790</td>\n",
       "      <td>NaN</td>\n",
       "      <td>471</td>\n",
       "      <td>137</td>\n",
       "      <td>91</td>\n",
       "      <td>51</td>\n",
       "      <td>29</td>\n",
       "      <td>26</td>\n",
       "      <td>15</td>\n",
       "      <td>35</td>\n",
       "      <td>13.170732</td>\n",
       "      <td>38</td>\n",
       "      <td>112.750824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1791</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Readers, @CAPS1 you imagine how life woul...</td>\n",
       "      <td>1791</td>\n",
       "      <td>NaN</td>\n",
       "      <td>410</td>\n",
       "      <td>103</td>\n",
       "      <td>103</td>\n",
       "      <td>49</td>\n",
       "      <td>21</td>\n",
       "      <td>17</td>\n",
       "      <td>24</td>\n",
       "      <td>31</td>\n",
       "      <td>4.733728</td>\n",
       "      <td>38</td>\n",
       "      <td>156.539091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1792</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear newspaper, I strongly believe that comput...</td>\n",
       "      <td>1792</td>\n",
       "      <td>NaN</td>\n",
       "      <td>496</td>\n",
       "      <td>132</td>\n",
       "      <td>122</td>\n",
       "      <td>39</td>\n",
       "      <td>38</td>\n",
       "      <td>22</td>\n",
       "      <td>34</td>\n",
       "      <td>47</td>\n",
       "      <td>4.824561</td>\n",
       "      <td>54</td>\n",
       "      <td>141.841194</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   essay_id  essay_set                                              essay  \\\n",
       "0      1788          1  Dear @ORGANIZATION1, @CAPS1 more and more peop...   \n",
       "1      1789          1  Dear @LOCATION1 Time @CAPS1 me tell you what I...   \n",
       "2      1790          1  Dear Local newspaper, Have you been spending a...   \n",
       "3      1791          1  Dear Readers, @CAPS1 you imagine how life woul...   \n",
       "4      1792          1  Dear newspaper, I strongly believe that comput...   \n",
       "\n",
       "   domain1_predictionid  domain2_predictionid  word_count  vocab_count  \\\n",
       "0                  1788                   NaN         275           77   \n",
       "1                  1789                   NaN         353           95   \n",
       "2                  1790                   NaN         471          137   \n",
       "3                  1791                   NaN         410          103   \n",
       "4                  1792                   NaN         496          132   \n",
       "\n",
       "   n_count  v_count  adj_count  adv_count  sent_len  freek  wrong_spell  \\\n",
       "0       67       29         21         15        13     26     8.771930   \n",
       "1       75       35         15         21        20     33     1.526718   \n",
       "2       91       51         29         26        15     35    13.170732   \n",
       "3      103       49         21         17        24     31     4.733728   \n",
       "4      122       39         38         22        34     47     4.824561   \n",
       "\n",
       "   beaut  perplexity  \n",
       "0     26  163.218737  \n",
       "1     25  154.934685  \n",
       "2     38  112.750824  \n",
       "3     38  156.539091  \n",
       "4     54  141.841194  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>rater1_domain1</th>\n",
       "      <th>rater2_domain1</th>\n",
       "      <th>rater3_domain1</th>\n",
       "      <th>domain1_score</th>\n",
       "      <th>rater1_domain2</th>\n",
       "      <th>rater2_domain2</th>\n",
       "      <th>domain2_score</th>\n",
       "      <th>...</th>\n",
       "      <th>vocab_count</th>\n",
       "      <th>n_count</th>\n",
       "      <th>v_count</th>\n",
       "      <th>adj_count</th>\n",
       "      <th>adv_count</th>\n",
       "      <th>sent_len</th>\n",
       "      <th>freek</th>\n",
       "      <th>wrong_spell</th>\n",
       "      <th>beaut</th>\n",
       "      <th>perplexity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear local newspaper, I think effects computer...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>103</td>\n",
       "      <td>84</td>\n",
       "      <td>39</td>\n",
       "      <td>24</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>25</td>\n",
       "      <td>7.333333</td>\n",
       "      <td>29</td>\n",
       "      <td>188.689232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @CAPS1 @CAPS2, I believe that using compu...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>129</td>\n",
       "      <td>117</td>\n",
       "      <td>61</td>\n",
       "      <td>21</td>\n",
       "      <td>15</td>\n",
       "      <td>20</td>\n",
       "      <td>36</td>\n",
       "      <td>8.920188</td>\n",
       "      <td>44</td>\n",
       "      <td>199.735366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>92</td>\n",
       "      <td>85</td>\n",
       "      <td>33</td>\n",
       "      <td>21</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>34</td>\n",
       "      <td>3.100775</td>\n",
       "      <td>29</td>\n",
       "      <td>168.040531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Local Newspaper, @CAPS1 I have found that...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>169</td>\n",
       "      <td>205</td>\n",
       "      <td>63</td>\n",
       "      <td>46</td>\n",
       "      <td>14</td>\n",
       "      <td>27</td>\n",
       "      <td>40</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>68</td>\n",
       "      <td>247.198548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @LOCATION1, I know having computers has a...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>131</td>\n",
       "      <td>115</td>\n",
       "      <td>50</td>\n",
       "      <td>23</td>\n",
       "      <td>21</td>\n",
       "      <td>30</td>\n",
       "      <td>40</td>\n",
       "      <td>12.442396</td>\n",
       "      <td>49</td>\n",
       "      <td>168.929019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   essay_id  essay_set                                              essay  \\\n",
       "0         1          1  Dear local newspaper, I think effects computer...   \n",
       "1         2          1  Dear @CAPS1 @CAPS2, I believe that using compu...   \n",
       "2         3          1  Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...   \n",
       "3         4          1  Dear Local Newspaper, @CAPS1 I have found that...   \n",
       "4         5          1  Dear @LOCATION1, I know having computers has a...   \n",
       "\n",
       "   rater1_domain1  rater2_domain1  rater3_domain1  domain1_score  \\\n",
       "0             4.0             4.0             NaN            8.0   \n",
       "1             5.0             4.0             NaN            9.0   \n",
       "2             4.0             3.0             NaN            7.0   \n",
       "3             5.0             5.0             NaN           10.0   \n",
       "4             4.0             4.0             NaN            8.0   \n",
       "\n",
       "   rater1_domain2  rater2_domain2  domain2_score     ...      vocab_count  \\\n",
       "0             NaN             NaN            NaN     ...              103   \n",
       "1             NaN             NaN            NaN     ...              129   \n",
       "2             NaN             NaN            NaN     ...               92   \n",
       "3             NaN             NaN            NaN     ...              169   \n",
       "4             NaN             NaN            NaN     ...              131   \n",
       "\n",
       "   n_count  v_count  adj_count  adv_count  sent_len  freek  wrong_spell  \\\n",
       "0       84       39         24         11        16     25     7.333333   \n",
       "1      117       61         21         15        20     36     8.920188   \n",
       "2       85       33         21          6        14     34     3.100775   \n",
       "3      205       63         46         14        27     40    12.500000   \n",
       "4      115       50         23         21        30     40    12.442396   \n",
       "\n",
       "   beaut  perplexity  \n",
       "0     29  188.689232  \n",
       "1     44  199.735366  \n",
       "2     29  168.040531  \n",
       "3     68  247.198548  \n",
       "4     49  168.929019  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_val.to_pickle(r\"C:\\Users\\PIYUSH\\Desktop\\validation_notscaled.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_pickle(r\"C:\\Users\\PIYUSH\\Downloads\\essay (1).pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle(r\"C:\\Users\\PIYUSH\\Desktop\\auto1.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
